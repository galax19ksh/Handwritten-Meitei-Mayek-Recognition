# -*- coding: utf-8 -*-
"""MMR55.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GVcEFRy8I73oVKsNh6uwknC81slFJ9Lf
"""

import torch
import pandas as pd
from PIL import Image
import os
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

from google.colab import drive
drive.mount('/content/drive')

class MMCharacterDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = sorted(os.listdir(root_dir))

        self.data = []
        self.targets = []

        for label_idx, label_name in enumerate(self.classes):
            label_dir = os.path.join(root_dir, label_name)
            for img_name in os.listdir(label_dir):
                img_path = os.path.join(label_dir, img_name)
                self.data.append(img_path)
                self.targets.append(label_idx)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = self.data[idx]
        label = self.targets[idx]

        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image, label

# Define data transformations
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

train_data_path = "/content/drive/MyDrive/datasets/mmr15/Train"
test_data_path = "/content/drive/MyDrive/datasets/mmr15/Test"

# Create instances of the dataset class for training and testing data
train_dataset = MMCharacterDataset(root_dir=train_data_path, transform=transform)
test_dataset = MMCharacterDataset(root_dir=test_data_path, transform=transform)

# Create DataLoader instances to iterate over batches of data during training and testing
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

# Example usage of the data loaders
#for batch_idx, (data, targets) in enumerate(train_loader):
    # data is a batch of images, targets is a batch of labels
    # Perform your training steps here
#    pass

# Get a batch of data
images, labels = next(iter(train_loader))

# Print the shapes of images and labels
print(f"Images shape: {images.shape}")
print(f"Labels shape: {labels.shape}")


import matplotlib.pyplot as plt
# Get a batch of images and labels
images, labels = next(iter(train_loader))

# Plot the images
fig, axs = plt.subplots(3, 3)
for i, (img, label) in enumerate(zip(images, labels)):
    ax = axs[i // 3, i % 3]
    ax.imshow(img.permute(1, 2, 0))
    ax.set_title(f"Label: {label}")
    ax.axis("off")

plt.suptitle("Sample Images from the Dataset")
plt.show()

num_labels = len(train_dataset.classes)
print(f"Number of labels in the dataset: {num_labels}")


import os

def count_images(root_dir):
  """
  Counts the number of images in each subfolder of a given root directory.

  Args:
    root_dir: The path to the root directory.

  Returns:
    A dictionary where the keys are the subfolder names and the values are the number of images in each subfolder.
  """

  image_counts = {}
  for subdir in os.listdir(root_dir):
    subfolder_path = os.path.join(root_dir, subdir)
    if os.path.isdir(subfolder_path):
      image_count = len([name for name in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, name))])
      image_counts[subdir] = image_count

  return image_counts

# Get the number of images in each subfolder of the training data directory
image_counts = count_images(train_data_path)

# Print the results
for subfolder, count in image_counts.items():
  print(f"Subfolder: {subfolder}, Image count: {count}")


import torch.nn as nn

class CNNModel(nn.Module):
    def __init__(self, num_classes):
        super(CNNModel, self).__init__()

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU()
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(256 * 8 * 8, 512)
        self.relu4 = nn.ReLU()
        self.dropout = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(512, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)

        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)

        x = self.conv3(x)
        x = self.relu3(x)
        x = self.pool3(x)

        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu4(x)
        x = self.dropout(x)
        x = self.fc2(x)

        return x

# Instantiate the model
model = CNNModel(num_classes=num_labels)

# Print the model summary
print(model)

model = CNNModel(num_classes=num_labels)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model.parameters(),
                            lr=0.01)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

print(f"Data type: {data.type()}")
print(f"Weight type: {model.conv1.weight.type()}")

# Use this code to run on cpu

#data = data.cpu()
#print(f"Data type: {data.type()}")
#print(f"Weight type: {model.conv1.weight.type()}")

model = model.to(device)



import warnings
warnings.filterwarnings('ignore')

from tqdm import tqdm

num_epochs = 50    #10 epochs --> 62% #25 epochs --> 90%  #50 epochs --> 92%
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

for epoch in range(num_epochs):
    # Set the model to training mode
    model.train()

    # Initialize variables to track accuracy and loss
    total_correct = 0
    total_samples = 0
    total_loss = 0.0

    # Initialize the progress bar
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{num_epochs}", leave=False)

    # Loop over each batch of data
    for batch_idx, (data, targets) in enumerate(progress_bar):
        # Move data and targets to the device
        data, targets = data.to(device), targets.to(device)

        # Forward pass
        output = model(data)

        # Calculate the loss
        loss = loss_fn(output, targets)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Update the progress bar
        progress_bar.set_postfix({"Loss": loss.item()})

        # Update the accuracy and loss metrics
        predictions = output.argmax(dim=1)
        total_correct += (predictions == targets).sum().item()
        total_samples += targets.size(0)
        total_loss += loss.item()

    # Calculate average loss and accuracy for this epoch
    epoch_loss = total_loss / len(train_loader.dataset)
    epoch_accuracy = 100 * total_correct / total_samples

    # Append the epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    # Evaluate the model
    model.eval()
    epoch_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for data, labels in test_loader:
            data, labels = data.to(device), labels.to(device)
            outputs = model(data)
            loss = loss_fn(outputs, labels)
            epoch_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_losses.append(epoch_loss / len(test_loader))
    test_accuracies.append(100 * correct / total)

    # Calculate and print the epoch accuracy and loss
    print(f"Epoch {epoch+1}/{num_epochs}: "
          f"Train Loss: {train_losses[-1]:.4f}, "
          f"Train Accuracy: {train_accuracies[-1]:.2f}%, "
          f"Test Loss: {test_losses[-1]:.4f}, "
          f"Test Accuracy: {test_accuracies[-1]:.2f}%")

# Calculate the total training time
end_time = time.time()
total_time = end_time - start_time

# Print the total training time
print(f"Total Training Time: {total_time:.2f} seconds")

# Save the model with full architecture
torch.save(model, "mmr_model1.pt")

"""THIS SECTION IS kinda SEPARATE."""

##TEMP CODE for Separate Model Testing
import torch

from google.colab import drive
drive.mount('/content/drive')

#map_location=torch.device('cpu')

# Check if the file exists
#!ls "/content/drive/MyDrive/MMR project/1 - mmr15/"

# Check if the file is a valid torch model
model = torch.load("/content/drive/MyDrive/MMR project/1 - mmr15/mmr_model1.pt")
print(model)

#model = torch.load("/content/drive/MyDrive/MMR project/1 - mmr15/mmr_model1.pt")


import matplotlib.pyplot as plt
# Define the path to the input image
input_image_path = "/content/drive/MyDrive/datasets/TUMMHCD-TEST-TRAIN/TUMMHCDtest/test_015/mmhc16_39.tif"

# Load the input image
input_image = Image.open(input_image_path).convert("RGB")

# Preprocess the input image
input_tensor = transform(input_image)
input_tensor = input_tensor.unsqueeze(0)  # Add a batch dimension

# Move the input tensor to the device
input_tensor = input_tensor.to(device)

# Make a prediction
with torch.no_grad():
    output = model(input_tensor)

# Get the predicted class
predicted_class = output.argmax(dim=1).item()

# Print the predicted class
print(f"Predicted class: {predicted_class}")

# Display the input image
plt.imshow(input_image)
plt.title(f"Predicted Class: {predicted_class}")
plt.axis("off")
plt.show()
